# Simple LangChain Demo

A simplified demonstration of essential LangChain concepts using PDF files, Gemini embeddings, and vector stores.

## ğŸ¯ What This Demo Shows

This application demonstrates the core concepts of LangChain in a simple, easy-to-understand way:

1. **Document Loading** - How to load and parse PDF files
2. **Text Chunking** - Breaking documents into manageable pieces
3. **Embeddings** - Converting text to numerical vectors using Gemini
4. **Vector Storage** - Storing and retrieving document vectors
5. **Semantic Search** - Finding relevant content by meaning
6. **RAG (Retrieval-Augmented Generation)** - Combining search with AI generation

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
npm install
```

### 2. Set Up Environment

Create a `.env` file with your Gemini API key:

```env
GEMINI_API_KEY=your_api_key_here
```

### 3. Add PDF Files

Create a `data` folder and add some PDF files:

```bash
mkdir data
# Add your PDF files to the data folder
```

### 4. Run the Demo

```bash
npm start
```

## ğŸ“ Project Structure

```
SimpleLangChain/
â”œâ”€â”€ pdf-loader.js            # PDF document loading
â”œâ”€â”€ text-splitter.js         # Text chunking
â”œâ”€â”€ vector-store.js          # Embeddings and vector storage
â”œâ”€â”€ chat.js                  # RAG chat interface
â”œâ”€â”€ langchain-demo.js        # Main application
â”œâ”€â”€ package.json
â””â”€â”€ README.md
```

## ğŸ”§ Key Components

### PDFLoader

- Loads and parses PDF files
- Extracts text and metadata
- Creates LangChain Document objects

### TextSplitter

- Breaks documents into chunks
- Configurable chunk size and overlap
- Essential for embedding generation

### VectorStore

- Creates embeddings using Gemini
- Stores documents as vectors
- Performs semantic similarity search

### Chat

- Implements RAG (Retrieval-Augmented Generation)
- Combines document search with AI responses
- Demonstrates the complete RAG pipeline

## ğŸ® Interactive Commands

When running the demo, you can use these commands:

- **Ask questions** - Get answers based on your documents
- `demo` - Show step-by-step RAG demonstration
- `compare` - Compare RAG vs simple chat responses
- `search <query>` - Perform semantic search
- `stats` - Show system statistics
- `help` - Show available commands
- `quit` - Exit the application

## ğŸ§  Understanding the Concepts

### 1. Document Processing

```
PDF File â†’ Text Extraction â†’ Document Object
```

### 2. Text Chunking

```
Large Document â†’ Small Chunks (1000 chars each)
```

### 3. Embeddings

```
Text Chunks â†’ Numerical Vectors (768 dimensions)
```

### 4. Vector Storage

```
Vectors â†’ Searchable Database
```

### 5. Semantic Search

```
Query â†’ Embedding â†’ Similarity Search â†’ Relevant Chunks
```

### 6. RAG Pipeline

```
Query â†’ Search â†’ Context â†’ LLM â†’ Answer
```

## ğŸ” How It Works

1. **Load PDFs** - The system reads PDF files and extracts text
2. **Chunk Text** - Large documents are split into smaller, manageable pieces
3. **Create Embeddings** - Each chunk is converted to a numerical vector using Gemini
4. **Store Vectors** - Embeddings are stored in a vector database
5. **Search** - When you ask a question, the system finds similar chunks
6. **Generate Answer** - The relevant chunks are sent to Gemini to generate an answer

## ğŸ¯ Learning Objectives

After running this demo, you'll understand:

- How to process PDF documents with LangChain
- The importance of text chunking for embeddings
- How embeddings enable semantic search
- The complete RAG pipeline
- The difference between simple chat and RAG

## ğŸ› ï¸ Customization

You can modify the demo by:

- Changing chunk size in `SimpleTextSplitter`
- Adjusting the number of search results
- Modifying the prompt template in `SimpleChat`
- Adding different document types

## ğŸ“š Next Steps

This demo provides a foundation for understanding LangChain. You can extend it by:

- Adding more document types (Word, Excel, etc.)
- Implementing different embedding models
- Using different vector stores (Pinecone, Weaviate, etc.)
- Adding conversation memory
- Implementing more sophisticated retrieval strategies

## ğŸ¤ Contributing

This is a learning demo. Feel free to modify and experiment with the code to deepen your understanding of LangChain concepts!
