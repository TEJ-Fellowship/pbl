# üí≥ Stripe Customer Support Agent ‚Äì API Integration & Billing Assistant

**Overview**

This project builds an intelligent customer support agent for Stripe's developer-focused ecosystem, specializing in API integration questions, billing disputes, payment method troubleshooting, and webhook debugging. Stripe's documentation is exceptionally well-structured and comprehensive, making it an ideal learning project for understanding how to handle technical support at scale. The agent needs to bridge both developer-facing technical content (API references, error codes) and business-facing support topics (refunds, chargebacks, account verification). This complexity makes it perfect for learning multi-domain RAG systems while working with real-world, production-grade documentation.

Stripe processes billions of dollars annually and their support system handles everything from "How do I create a payment intent?" to "Why is my webhook failing?" ‚Äì making this agent valuable for learning how to build context-aware assistants that can handle both conceptual questions and debugging scenarios.

**Real-World Inspiration**  
Modeled after [Stripe's AI-powered documentation assistant](https://stripe.com/docs) and their support chat system. Stripe uses semantic search across their docs and has one of the best-structured technical knowledge bases in the industry. Their actual support combines LLM-powered search with escalation to human experts for account-specific issues.

**Data Sources**  
Specific URLs to scrape:

- **Main Documentation Hub:** https://stripe.com/docs
- **API Reference:** https://stripe.com/docs/api
- **Payment Methods Guide:** https://stripe.com/docs/payments/payment-methods
- **Webhooks Guide:** https://stripe.com/docs/webhooks
- **Error Codes:** https://stripe.com/docs/error-codes
- **Support Articles:** https://support.stripe.com/topics
- **Integration Guides:** https://stripe.com/docs/development/get-started
- **Billing & Subscriptions:** https://stripe.com/docs/billing
- **Disputes & Chargebacks:** https://stripe.com/docs/disputes

_(Note: Respect Stripe's robots.txt at https://stripe.com/robots.txt and implement rate limiting ‚Äì max 1 request per second during scraping)_

---

## **Tier 1: Basic RAG Chat** ‚è±Ô∏è _Days 1-3_

**Core Functionality:**

- **Data Ingestion:**

  - Use `Playwright` (Node.js) or `Cheerio` + `Axios` to scrape Stripe docs HTML
  - Focus on 3 main sections: API Reference, Webhooks Guide, Error Codes
  - Clean HTML using `node-html-parser` or `cheerio` to extract main content (remove nav, footer, sidebars)
  - Store raw markdown/text in `./data/stripe_docs/` directory as JSON files

- **Chunking Strategy:**

  - Use `langchain` (JavaScript/TypeScript version) with `RecursiveCharacterTextSplitter`
  - Chunk size: 800 tokens with 100 token overlap
  - Split on code blocks first (preserve code examples intact)
  - Include document title in each chunk's metadata
  - Use `js-tiktoken` for accurate token counting

- **Vector Storage:**

  - Generate embeddings with `OpenAI text-embedding-3-small` via `openai` npm package
  - Store in **Pinecone** index (dimension: 1536) using `@pinecone-database/pinecone`
  - Metadata: `{source_url, doc_title, section_name}`
  - Alternative: **Chroma** with `chromadb` npm client for local development

- **Simple Retrieval:**

  - Basic cosine similarity search (top-k=4)
  - Use Pinecone query API or Chroma query
  - Return raw chunks without re-ranking

- **Chat Interface:**

  - Terminal-based Node.js script using `readline` or `inquirer`
  - Display retrieved chunks before final answer
  - Example: "How do I handle webhook signatures?"

- **Response Generation:**
  - Use GPT-4 via `openai` npm package
  - System prompt: "You are a Stripe API support assistant. Answer using only the provided documentation context."
  - Single-turn: no conversation memory
  - Include retrieved context in prompt

**Tech Stack:**

note: get the latest versions you can find. the below is only a sample generated by AI

```json
{
  "dependencies": {
    "@langchain/openai": "^0.0.28",
    "@langchain/core": "^0.1.52",
    "@pinecone-database/pinecone": "^2.0.1",
    "openai": "^4.28.0",
    "cheerio": "^1.0.0-rc.12",
    "axios": "^1.6.7",
    "playwright": "^1.42.0",
    "node-html-parser": "^6.1.12",
    "js-tiktoken": "^1.0.10",
    "dotenv": "^16.4.5",
    "inquirer": "^9.2.15"
  }
}
```

**Project Structure:**

```
stripe-support-agent/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ scraper.js          # Scrape Stripe docs
‚îÇ   ‚îú‚îÄ‚îÄ ingest.js           # Chunk & embed documents
‚îÇ   ‚îú‚îÄ‚îÄ retriever.js        # Vector search logic
‚îÇ   ‚îú‚îÄ‚îÄ chat.js             # Terminal Q&A interface
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ chunker.js      # Text splitting utilities
‚îÇ       ‚îî‚îÄ‚îÄ cleaner.js      # HTML cleaning
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ stripe_docs/        # Scraped content
‚îú‚îÄ‚îÄ .env                    # API keys
‚îú‚îÄ‚îÄ package.json
‚îî‚îÄ‚îÄ README.md
```

**Deliverables:**

- `scraper.js` ‚Äì Stripe docs scraper
- `ingest.js` ‚Äì Chunk & embed documents
- `chat.js` ‚Äì Terminal Q&A interface
- `package.json` ‚Äì Dependencies

**Sample Code (scraper.js):**

```javascript
import axios from "axios";
import * as cheerio from "cheerio";
import fs from "fs/promises";
import path from "path";

const SOURCES = {
  api: "https://stripe.com/docs/api",
  webhooks: "https://stripe.com/docs/webhooks",
  errors: "https://stripe.com/docs/error-codes",
};

async function scrapeDoc(url, category) {
  await new Promise((resolve) => setTimeout(resolve, 1000)); // Rate limit

  const response = await axios.get(url);
  const $ = cheerio.load(response.data);

  // Remove navigation, footer, ads
  $("nav, footer, .sidebar, .header").remove();

  const content = $("main").text() || $("article").text();
  const title = $("h1").first().text();

  return {
    url,
    category,
    title: title.trim(),
    content: content.trim(),
    scrapedAt: new Date().toISOString(),
  };
}

async function main() {
  const docs = [];

  for (const [category, url] of Object.entries(SOURCES)) {
    console.log(`Scraping ${category}...`);
    const doc = await scrapeDoc(url, category);
    docs.push(doc);
  }

  await fs.mkdir("./data/stripe_docs", { recursive: true });
  await fs.writeFile(
    "./data/stripe_docs/scraped.json",
    JSON.stringify(docs, null, 2)
  );

  console.log(`‚úÖ Scraped ${docs.length} documents`);
}

main();
```

---

## **Tier 2: Production RAG + Context Management** ‚è±Ô∏è _Days 4-7_

**Enhanced Features:**

- **Multi-Source Ingestion:**

  - Scrape all 9 data sources listed above
  - Detect and parse different content types using custom parsers:
    - API reference pages (extract JSON examples with `cheerio`)
    - Tutorial articles (step-by-step guides)
    - Error code tables (structured data extraction)
  - Use `RecursiveCharacterTextSplitter` for guides, custom splitter for API refs

- **Metadata Enrichment:**

  - Tag chunks with: `source_url`, `doc_type` (api/guide/support), `category` (billing/webhooks/payments), `last_updated`, `code_language` (if contains code)
  - Extract code snippets as separate chunks with backreference to parent explanation
  - Use regex to detect code blocks and programming languages

- **Hybrid Search:**

  - Implement BM25 keyword search using `natural` library or `flexsearch`
  - Combine semantic (Pinecone) + keyword (BM25) scores with 0.7/0.3 weighting
  - Especially important for exact error codes (e.g., "card_declined")
  - Create fusion ranking algorithm

- **Conversation History:**

  - Maintain sliding window of last 8 messages (4 turns)
  - Use `@langchain/memory` with `BufferWindowMemory`
  - Store in MongoDB for persistence across sessions
  - Include previous Q&A context in retrieval query reformulation

- **Context Windowing:**

  - Track token count using `js-tiktoken`
  - Truncate history if conversation + retrieved docs > 6000 tokens
  - Prioritize most recent turn and highest-relevance chunks

- **Re-ranking:**

  - Implement cross-encoder re-ranking using `@xenova/transformers` (Hugging Face Transformers.js)
  - Model: `cross-encoder/ms-marco-MiniLM-L-6-v2`
  - Re-score top 10 results, return top 4
  - Runs client-side in Node.js (no Python required)

- **Response Improvements:**

  - Cite sources: "According to the [Webhooks Guide](url)..."
  - Show confidence: "Based on the documentation (High confidence)" or "I couldn't find definitive info (Low confidence)"
  - Format code blocks with `markdown-it` for proper rendering
  - Handle edge cases with fallback responses

- **Web UI:**
  - Build **React** chat interface with:
    - Message history display
    - Source citations panel (expandable)
    - Code copy buttons with `react-syntax-highlighter`
    - "Was this helpful?" feedback buttons
  - **Backend:** Express.js REST API
    - `POST /api/chat` ‚Äì Send message, get response
    - `GET /api/history/:sessionId` ‚Äì Retrieve conversation
  - **Database:** MongoDB for conversation storage
  - **Styling:** Tailwind CSS for modern UI

**Tech Stack (Additional):**

```json
{
  "dependencies": {
    "express": "^4.18.2",
    "mongodb": "^6.3.0",
    "mongoose": "^8.1.1",
    "natural": "^6.10.0",
    "flexsearch": "^0.7.43",
    "@xenova/transformers": "^2.14.0",
    "markdown-it": "^14.0.0",
    "cors": "^2.8.5"
  },
  "devDependencies": {
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "vite": "^5.1.0",
    "@vitejs/plugin-react": "^4.2.1",
    "tailwindcss": "^3.4.1"
  }
}
```

**Project Structure (Updated):**

```
stripe-support-agent/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ server.js           # Express API server
‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chat.js         # Chat endpoints
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ retriever.js    # Hybrid search
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ reranker.js     # Cross-encoder
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ llm.js          # OpenAI integration
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Conversation.js # MongoDB schema
‚îÇ   ‚îî‚îÄ‚îÄ config/
‚îÇ       ‚îî‚îÄ‚îÄ db.js           # MongoDB connection
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ChatWindow.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ MessageList.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SourcePanel.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ InputBox.jsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.jsx
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.jsx
‚îÇ   ‚îú‚îÄ‚îÄ index.html
‚îÇ   ‚îú‚îÄ‚îÄ vite.config.js
‚îÇ   ‚îî‚îÄ‚îÄ tailwind.config.js
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ scraper.js
‚îÇ   ‚îî‚îÄ‚îÄ ingest.js
‚îî‚îÄ‚îÄ package.json
```

**Deliverables:**

- Enhanced scraper with multi-source support
- Hybrid retrieval pipeline (semantic + BM25)
- React chat UI with Tailwind CSS
- Express.js REST API
- MongoDB conversation memory
- Re-ranking with Transformers.js

**Sample Code (Hybrid Search):**

```javascript
import { PineconeStore } from "@langchain/pinecone";
import FlexSearch from "flexsearch";

class HybridRetriever {
  constructor(vectorStore, documents) {
    this.vectorStore = vectorStore;
    this.bm25Index = new FlexSearch.Document({
      tokenize: "forward",
      document: {
        id: "id",
        index: ["content"],
      },
    });

    // Index documents for BM25
    documents.forEach((doc, idx) => {
      this.bm25Index.add({ id: idx, content: doc.pageContent });
    });
    this.documents = documents;
  }

  async retrieve(query, k = 4) {
    // Semantic search
    const semanticResults = await this.vectorStore.similaritySearchWithScore(
      query,
      10
    );

    // Keyword search
    const keywordResults = this.bm25Index.search(query, 10);

    // Fusion ranking (0.7 semantic + 0.3 keyword)
    const merged = this.fuseResults(semanticResults, keywordResults, 0.7, 0.3);

    return merged.slice(0, k);
  }

  fuseResults(semantic, keyword, alpha, beta) {
    // Normalize and combine scores
    const scores = new Map();

    semantic.forEach(([doc, score], idx) => {
      const normalized = 1 / (idx + 1); // Reciprocal rank
      scores.set(
        doc.metadata.id,
        (scores.get(doc.metadata.id) || 0) + alpha * normalized
      );
    });

    keyword.forEach((result, idx) => {
      const docId = result.id;
      const normalized = 1 / (idx + 1);
      scores.set(docId, (scores.get(docId) || 0) + beta * normalized);
    });

    return Array.from(scores.entries())
      .sort((a, b) => b[1] - a[1])
      .map(([id, score]) => ({ document: this.documents[id], score }));
  }
}
```

---

## **Tier 3: MCP + Advanced Agent Features** ‚è±Ô∏è _Days 8-11_

**Agentic Capabilities:**

- **MCP Tool Integration (using `@modelcontextprotocol/sdk`):**

  1. **Web Search Fallback** (Brave Search MCP server)

     - Install: `npm install @modelcontextprotocol/server-brave-search`
     - Trigger when confidence < 0.6 or no relevant docs found
     - Search: "Stripe [user_query] site:stripe.com OR site:support.stripe.com"
     - Use for recent changes not yet in scraped docs

  2. **Calculator Tool** (Built-in MCP)

     - Use `mathjs` library wrapped as MCP tool
     - Handle: "If I charge 3.2% + $0.30 per transaction, what's the fee on $1,247.50?"
     - Stripe fee calculations for different regions

  3. **Status Page Checker** (Custom MCP server)

     - Check https://status.stripe.com API with `axios`
     - Detect if current issues exist (e.g., "Webhooks experiencing delays")
     - Proactively mention: "Note: Stripe is currently investigating webhook delivery delays"

  4. **Date/Time Tool** (Built-in MCP)

     - Use `date-fns` for time-sensitive queries
     - Handle: "Is Stripe down right now?" (check current time against status page)

  5. **Code Validator** (Custom MCP tool)
     - Validate Stripe API endpoint URLs using regex
     - Check HTTP method compatibility with endpoint
     - Parse code snippets to identify potential errors

- **Multi-Turn Conversations:**

  - Handle follow-ups: "What about recurring payments?" after discussing one-time charges
  - Maintain context: Remember if user mentioned using Node.js SDK vs. REST API
  - Clarification: "Are you asking about Stripe Connect or standard payments?"
  - Context compression: Summarize long conversations every 10 turns using GPT-4

- **Source Attribution:**

  - Display: "Answer synthesized from 3 sources:" with expandable cards
  - Show chunk relevance scores as progress bars
  - Link directly to doc section with anchor tags
  - Track which chunks contributed to each sentence

- **Confidence Scoring:**

  - Calculate based on:
    - Retrieval similarity scores (semantic + keyword)
    - Cross-encoder re-ranking scores
    - Presence of exact entity matches (error codes, API methods)
  - Algorithm: `confidence = 0.4 * avgSemanticScore + 0.3 * rerankerScore + 0.3 * exactMatchBonus`
  - Display: üü¢ High (>0.8) | üü° Medium (0.5-0.8) | üî¥ Low (<0.5)
  - Auto-escalate if confidence < 0.5

- **Query Classification:**

  - Classify into: `technical_api`, `billing`, `disputes`, `webhooks`, `account`, `integration`
  - Use few-shot prompting with GPT-4 or fine-tuned model
  - Alternative: Simple rule-based classifier with keyword matching
  - Route to specialized prompt templates per category

- **Feedback Loop:**

  - üëç üëé buttons on each response
  - Store in MongoDB: `{query, retrieved_chunks, response, feedback, timestamp, sessionId}`
  - Daily aggregation script to identify patterns
  - Auto-retrain retrieval weights based on negative feedback

- **Conversation Analytics:**
  - Track in **PostgreSQL** (for better analytics):
    - Top 20 questions per week (using GROUP BY)
    - Categories with highest "I don't know" rate
    - Avg turns per conversation
    - Escalation rate (when agent defers to human)
  - Use `pg` npm package for database connection
  - Build analytics dashboard with Chart.js or Recharts

**Tech Stack (Additional):**

```json
{
  "dependencies": {
    "@modelcontextprotocol/sdk": "^0.5.0",
    "@modelcontextprotocol/server-brave-search": "^0.2.0",
    "mathjs": "^12.3.2",
    "date-fns": "^3.3.1",
    "pg": "^8.11.3",
    "chart.js": "^4.4.1",
    "react-chartjs-2": "^5.2.0"
  }
}
```

**MCP Integration Example:**

```javascript
import { MCPClient } from "@modelcontextprotocol/sdk/client/index.js";
import { BraveSearchServer } from "@modelcontextprotocol/server-brave-search";

class AgentOrchestrator {
  constructor() {
    this.mcpClient = new MCPClient();
    this.tools = new Map();
  }

  async initializeTools() {
    // Register Brave Search
    const braveSearch = new BraveSearchServer({
      apiKey: process.env.BRAVE_API_KEY,
    });
    await this.mcpClient.connectToServer(braveSearch);

    // Register Calculator
    this.tools.set("calculator", this.createCalculatorTool());

    // Register Status Checker
    this.tools.set("status_checker", this.createStatusTool());
  }

  async decideToolUse(query, confidence) {
    if (confidence < 0.6) {
      return ["web_search"]; // Fallback to web
    }

    if (query.match(/\d+\.\d+%|\$\d+/)) {
      return ["calculator"]; // Contains pricing
    }

    if (query.toLowerCase().includes("down") || query.includes("not working")) {
      return ["status_checker"];
    }

    return []; // No tools needed
  }

  async executeTools(toolNames, query) {
    const results = {};

    for (const toolName of toolNames) {
      if (toolName === "web_search") {
        results.web = await this.mcpClient.callTool("brave_search", {
          query: `Stripe ${query} site:stripe.com`,
        });
      } else if (this.tools.has(toolName)) {
        results[toolName] = await this.tools.get(toolName)(query);
      }
    }

    return results;
  }

  createCalculatorTool() {
    const math = require("mathjs");
    return async (expression) => {
      try {
        // Extract math expressions from natural language
        const matches = expression.match(/[\d\.\+\-\*\/\(\)%]+/g);
        if (matches) {
          return math.evaluate(matches[0]);
        }
      } catch (err) {
        return null;
      }
    };
  }

  createStatusTool() {
    return async () => {
      const response = await axios.get(
        "https://status.stripe.com/api/v2/status.json"
      );
      return response.data.status;
    };
  }
}
```

**Deliverables:**

- 5 MCP tool integrations
- Multi-turn conversation engine with context compression
- Confidence scoring algorithm
- Query classifier
- Feedback collection in MongoDB
- PostgreSQL analytics database
- Analytics dashboard component

---

## **Tier 4: Enterprise-Grade Production System** ‚è±Ô∏è _Days 12-14_

**Moonshot Features:**

- **Multi-Tenancy:**

  - Support multiple companies (e.g., Stripe + Twilio + Shopify docs)
  - Namespace vector indices: `tenant_{id}_docs` in Pinecone
  - Per-tenant config in PostgreSQL: API keys, usage quotas, custom branding
  - Middleware to inject tenant context on every request

- **Admin Dashboard:**

  - **Knowledge Management:**
    - Upload custom docs via drag-drop (parse PDF/DOCX with `pdf-parse` and `mammoth`)
    - Re-scrape Stripe docs on schedule using `node-cron`
    - View document coverage: % of doc categories indexed
    - Manual chunk editing interface (React + Monaco Editor)
  - **Analytics:**
    - Conversation volume over time (line charts)
    - Top unanswered questions (knowledge gaps table)
    - User satisfaction trends (CSAT line chart)
    - Token usage & cost tracking ($ per conversation pie chart)
  - **Performance Monitoring:**
    - P95 latency per query type (histogram)
    - Cache hit rate for repeated questions
    - Retrieval accuracy metrics
  - Built with: **React** + **Recharts** + **Express** backend

- **A/B Testing Framework:**

  - Test variants stored in PostgreSQL:
    - Chunking: 500 vs 1000 tokens
    - Retrieval: top-3 vs top-5 chunks
    - Prompts: different system prompts
    - Models: GPT-4 vs GPT-4-turbo vs Claude Sonnet
  - Implement with middleware that randomly assigns variant
  - Statistical testing with `simple-statistics` library
  - Auto-promote winning variant after 1000 trials (Chi-square test)

- **Human Handoff:**

  - Detect escalation triggers:
    - User frustration: sentiment analysis with `sentiment` library
    - Account-specific keywords: "suspended", "banned", "locked"
    - Confidence < 0.4 for 3 consecutive turns
  - Create webhook to ticketing system (Zendesk API) with conversation context
  - Seamless transition message in UI

- **Integration Hub:**

  - **Slack Bot:**
    - Use `@slack/bolt` framework
    - Slash command: `/stripe-help [question]`
    - Thread-based conversations with conversation memory
  - **Discord Bot:**
    - Use `discord.js` library
    - React with ‚úÖ when answer marked helpful
  - **Webhooks:**
    - POST to customer's endpoint on events
    - Event types: `conversation.started`, `escalated`, `feedback_received`
    - Signed with HMAC for security
  - **REST API:**
    - `POST /api/chat` ‚Äì Send message, get response
    - `GET /api/conversations/{id}` ‚Äì Retrieve history
    - JWT authentication with `jsonwebtoken`
    - Rate limiting with `express-rate-limit`

- **Advanced RAG:**

  - **Query Expansion:**
    - Generate 3 paraphrased versions with GPT-4
    - Retrieve for each, merge with fusion ranking
  - **HyDE (Hypothetical Document Embeddings):**
    - Generate hypothetical ideal answer
    - Embed it, search for similar real docs
  - **Parent-Child Chunks:**
    - Store small chunks (400 tokens) for retrieval
    - Retrieve parent document (2000 tokens) for LLM
    - Track relationships in MongoDB

- **Guardrails:**

  - **PII Detection:**
    - Regex for API keys: `sk_(live|test)_[a-zA-Z0-9]+`
    - Email detection, credit card patterns
    - Mask before logging
  - **Toxicity Filter:**
    - Use `@tensorflow-models/toxicity` (TensorFlow.js)
    - Block profanity, harassment
  - **Prompt Injection Defense:**
    - Detect patterns: "ignore previous", "system:"
    - Sanitize with `validator` library
  - **Rate Limiting:**
    - Redis-based token bucket with `ioredis`
    - 20 messages per user per hour

- **Evaluation Suite:**
  - **Golden Q&A Dataset:**
    - Store in JSON: 200 Stripe questions with verified answers
    - Cover all doc categories
  - **Automated Testing:**
    - Run golden set with `jest` on every deploy
    - Calculate accuracy metrics
    - RAGAS-style metrics (faithfulness, relevance)
  - **CI/CD Integration:**
    - GitHub Actions workflow
    - Alert if metrics drop >5%
    - Automated deployment to production

**Tech Stack (Additional):**

```json
{
  "dependencies": {
    "@slack/bolt": "^3.17.1",
    "discord.js": "^14.14.1",
    "jsonwebtoken": "^9.0.2",
    "express-rate-limit": "^7.1.5",
    "ioredis": "^5.3.2",
    "node-cron": "^3.0.3",
    "pdf-parse": "^1.1.1",
    "mammoth": "^1.6.0",
    "sentiment": "^5.0.2",
    "@tensorflow-models/toxicity": "^1.2.2",
    "validator": "^13.11.0",
    "simple-statistics": "^7.8.3"
  },
  "devDependencies": {
    "jest": "^29.7.0",
    "@testing-library/react": "^14.2.1"
  }
}
```

**Project Structure (Final):**

```
stripe-support-agent/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ server.js
‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ admin.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ webhooks.js
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ analytics.js
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rag/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ retriever.js
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ reranker.js
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hyde.js
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ query-expansion.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mcp/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ orchestrator.js
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tools/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ guardrails/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pii-detector.js
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ toxicity-filter.js
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ integrations/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ slack-bot.js
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ discord-bot.js
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Conversation.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Tenant.js
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Analytics.js
‚îÇ   ‚îú‚îÄ‚îÄ middleware/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auth.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rate-limit.js
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tenant.js
‚îÇ   ‚îî‚îÄ‚îÄ config/
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ admin/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ analytics/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pages/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Chat.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Admin.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Dashboard.jsx
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ App.jsx
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ scraper.js
‚îÇ   ‚îú‚îÄ‚îÄ ingest.js
‚îÇ   ‚îú‚îÄ‚îÄ cron-rescrape.js
‚îÇ   ‚îî‚îÄ‚îÄ run-evaluation.js
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ golden-qa.json
‚îÇ   ‚îî‚îÄ‚îÄ integration.test.js
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îî‚îÄ‚îÄ ci-cd.yml
‚îî‚îÄ‚îÄ docker-compose.yml
```

**Deliverables:**

- Full admin dashboard (React)
- Multi-tenant architecture with namespace isolation
- A/B testing framework with statistical analysis
- Slack + Discord bot integration
- Advanced RAG (HyDE + query expansion + parent-child)
- Comprehensive guardrails (PII, toxicity, rate limiting)
- Automated evaluation suite with CI/CD
- Docker containerization with docker-compose
- Production deployment guide (AWS/Vercel)

---

## üìä **Success Metrics**

Track these KPIs to measure agent effectiveness:

| Metric                 | Tier 1            | Tier 2                  | Tier 3       | Tier 4            |
| ---------------------- | ----------------- | ----------------------- | ------------ | ----------------- |
| **Answer Accuracy**    | Manual spot-check | >70% helpful (feedback) | >80% helpful | >85% (RAGAS)      |
| **Avg Response Time**  | <5s               | <3s                     | <2s (cached) | <1.5s (optimized) |
| **Escalation Rate**    | N/A               | N/A                     | <20%         | <15%              |
| **User Satisfaction**  | N/A               | Thumbs up/down          | CSAT score   | >4.2/5 CSAT       |
| **Knowledge Coverage** | 3 doc sections    | All 9 sources           | + web search | + custom docs     |

---

## üöÄ **2-Week Timeline**

### **Week 1: Core RAG System**

- **Days 1-3 (Tier 1):** Basic scraper, embedding pipeline, terminal chat
- **Days 4-7 (Tier 2):** Multi-source scraping, React UI, Express API, hybrid search, MongoDB integration

### **Week 2: Advanced Features & Production**

- **Days 8-11 (Tier 3):** MCP tools, confidence scoring, analytics, multi-turn conversations
- **Days 12-14 (Tier 4):** Admin dashboard, guardrails, integrations, deployment, testing

**Daily Breakdown:**

| Day | Focus                       | Deliverable              |
| --- | --------------------------- | ------------------------ |
| 1   | Scraper setup               | 3 sources scraped        |
| 2   | Embedding & vector DB       | Pinecone index populated |
| 3   | Terminal chat               | Basic Q&A working        |
| 4   | Multi-source scraper        | All 9 sources scraped    |
| 5   | Hybrid search + reranking   | Improved retrieval       |
| 6   | React UI + Express API      | Web interface            |
| 7   | Conversation memory         | Multi-turn working       |
| 8   | MCP tool integration        | 3+ tools connected       |
| 9   | Confidence & classification | Smart routing            |
| 10  | Analytics dashboard         | PostgreSQL + charts      |
| 11  | Feedback loop               | Thumbs up/down           |
| 12  | Admin panel                 | Knowledge management     |
| 13  | Guardrails + testing        | Security + CI/CD         |
| 14  | Deployment + polish         | Production-ready         |

---

## üöÄ **Quick Start**

```bash
# Clone starter template
git clone <repo-url> stripe-support-agent
cd stripe-support-agent

# Install dependencies
npm install

# Set up environment
cp .env.example .env
# Add: OPENAI_API_KEY, PINECONE_API_KEY, PINECONE_INDEX_NAME, MONGODB_URI

# Scrape Stripe docs (Tier 1: 3 sources)
node scripts/scraper.js --sources api,webhooks,errors --limit 50

# Ingest into Pinecone
node scripts/ingest.js

# Start terminal chat (Tier 1)
node src/chat.js

# OR start web app (Tier 2+)
npm run dev:backend  # Terminal 1
npm run dev:frontend # Terminal 2
# Open http://localhost:5173
```

**Sample Interaction:**

```
You: How do I verify webhook signatures in Node.js?

Agent: [üü¢ High Confidence - 0.89]

To verify webhook signatures in Node.js, Stripe signs each webhook with your
endpoint's secret. Here's how to verify:

[Code block showing Node.js example]

üìö Sources:
- Webhooks Guide (stripe.com/docs/webhooks)
- Node.js SDK Reference

Was this helpful? üëç üëé
```

---

## ‚ö†Ô∏è **Ethical Scraping Guidelines**

- ‚úÖ Stripe's docs are publicly accessible and meant for developer use
- ‚úÖ Respect `robots.txt` ‚Äì Stripe allows doc crawling
- ‚úÖ Implement 1 req/sec rate limit during scraping
- ‚úÖ Cache scraped content ‚Äì don't re-scrape on every run
- ‚úÖ Use official API when available (Stripe doesn't have doc API)
- ‚ùå Never scrape user dashboards or authenticated content
- ‚ùå Don't republish Stripe's docs verbatim (use for retrieval only)

---

## üéì **Learning Outcomes**

By building this agent in 2 weeks, you'll master:

- **Week 1:** RAG fundamentals, vector databases, React/Express full-stack, hybrid search, conversation memory
- **Week 2:** MCP tool orchestration, agent reasoning, analytics, production deployment, testing & CI/CD

This project evolves from a weekend prototype to a production-ready system that could genuinely reduce Stripe's support ticket volume. **Every tier is immediately deployable and useful**, with clear 2-week milestones.
