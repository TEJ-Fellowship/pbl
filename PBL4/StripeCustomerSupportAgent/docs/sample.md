# 💳 Stripe Customer Support Agent – API Integration & Billing Assistant

**Overview**

This project builds an intelligent customer support agent for Stripe's developer-focused ecosystem, specializing in API integration questions, billing disputes, payment method troubleshooting, and webhook debugging. Stripe's documentation is exceptionally well-structured and comprehensive, making it an ideal learning project for understanding how to handle technical support at scale. The agent needs to bridge both developer-facing technical content (API references, error codes) and business-facing support topics (refunds, chargebacks, account verification). This complexity makes it perfect for learning multi-domain RAG systems while working with real-world, production-grade documentation.

Stripe processes billions of dollars annually and their support system handles everything from "How do I create a payment intent?" to "Why is my webhook failing?" – making this agent valuable for learning how to build context-aware assistants that can handle both conceptual questions and debugging scenarios.

**Real-World Inspiration**  
Modeled after [Stripe's AI-powered documentation assistant](https://stripe.com/docs) and their support chat system. Stripe uses semantic search across their docs and has one of the best-structured technical knowledge bases in the industry. Their actual support combines LLM-powered search with escalation to human experts for account-specific issues.

**Data Sources**  
Specific URLs to scrape:

- **Main Documentation Hub:** https://stripe.com/docs
- **API Reference:** https://stripe.com/docs/api
- **Payment Methods Guide:** https://stripe.com/docs/payments/payment-methods
- **Webhooks Guide:** https://stripe.com/docs/webhooks
- **Error Codes:** https://stripe.com/docs/error-codes
- **Support Articles:** https://support.stripe.com/topics
- **Integration Guides:** https://stripe.com/docs/development/get-started
- **Billing & Subscriptions:** https://stripe.com/docs/billing
- **Disputes & Chargebacks:** https://stripe.com/docs/disputes

_(Note: Respect Stripe's robots.txt at https://stripe.com/robots.txt and implement rate limiting – max 1 request per second during scraping)_

---

## **Tier 1: Basic RAG Chat** ⏱️ _Days 1-3_

**Core Functionality:**

- **Data Ingestion:**

  - Use `Playwright` (Node.js) or `Cheerio` + `Axios` to scrape Stripe docs HTML
  - Focus on 3 main sections: API Reference, Webhooks Guide, Error Codes
  - Clean HTML using `node-html-parser` or `cheerio` to extract main content (remove nav, footer, sidebars)
  - Store raw markdown/text in `./data/stripe_docs/` directory as JSON files

- **Chunking Strategy:**

  - Use `langchain` (JavaScript/TypeScript version) with `RecursiveCharacterTextSplitter`
  - Chunk size: 800 tokens with 100 token overlap
  - Split on code blocks first (preserve code examples intact)
  - Include document title in each chunk's metadata
  - Use `js-tiktoken` for accurate token counting

- **Vector Storage:**

  - Generate embeddings with `OpenAI text-embedding-3-small` via `openai` npm package
  - Store in **Pinecone** index (dimension: 1536) using `@pinecone-database/pinecone`
  - Metadata: `{source_url, doc_title, section_name}`
  - Alternative: **Chroma** with `chromadb` npm client for local development

- **Simple Retrieval:**

  - Basic cosine similarity search (top-k=4)
  - Use Pinecone query API or Chroma query
  - Return raw chunks without re-ranking

- **Chat Interface:**

  - Terminal-based Node.js script using `readline` or `inquirer`
  - Display retrieved chunks before final answer
  - Example: "How do I handle webhook signatures?"

- **Response Generation:**
  - Use GPT-4 via `openai` npm package
  - System prompt: "You are a Stripe API support assistant. Answer using only the provided documentation context."
  - Single-turn: no conversation memory
  - Include retrieved context in prompt

**Tech Stack:**

note: get the latest versions you can find. the below is only a sample generated by AI

```json
{
  "dependencies": {
    "@langchain/openai": "^0.0.28",
    "@langchain/core": "^0.1.52",
    "@pinecone-database/pinecone": "^2.0.1",
    "openai": "^4.28.0",
    "cheerio": "^1.0.0-rc.12",
    "axios": "^1.6.7",
    "playwright": "^1.42.0",
    "node-html-parser": "^6.1.12",
    "js-tiktoken": "^1.0.10",
    "dotenv": "^16.4.5",
    "inquirer": "^9.2.15"
  }
}
```

**Project Structure:**

```
stripe-support-agent/
├── src/
│   ├── scraper.js          # Scrape Stripe docs
│   ├── ingest.js           # Chunk & embed documents
│   ├── retriever.js        # Vector search logic
│   ├── chat.js             # Terminal Q&A interface
│   └── utils/
│       ├── chunker.js      # Text splitting utilities
│       └── cleaner.js      # HTML cleaning
├── data/
│   └── stripe_docs/        # Scraped content
├── .env                    # API keys
├── package.json
└── README.md
```

**Deliverables:**

- `scraper.js` – Stripe docs scraper
- `ingest.js` – Chunk & embed documents
- `chat.js` – Terminal Q&A interface
- `package.json` – Dependencies

**Sample Code (scraper.js):**

```javascript
import axios from "axios";
import * as cheerio from "cheerio";
import fs from "fs/promises";
import path from "path";

const SOURCES = {
  api: "https://stripe.com/docs/api",
  webhooks: "https://stripe.com/docs/webhooks",
  errors: "https://stripe.com/docs/error-codes",
};

async function scrapeDoc(url, category) {
  await new Promise((resolve) => setTimeout(resolve, 1000)); // Rate limit

  const response = await axios.get(url);
  const $ = cheerio.load(response.data);

  // Remove navigation, footer, ads
  $("nav, footer, .sidebar, .header").remove();

  const content = $("main").text() || $("article").text();
  const title = $("h1").first().text();

  return {
    url,
    category,
    title: title.trim(),
    content: content.trim(),
    scrapedAt: new Date().toISOString(),
  };
}

async function main() {
  const docs = [];

  for (const [category, url] of Object.entries(SOURCES)) {
    console.log(`Scraping ${category}...`);
    const doc = await scrapeDoc(url, category);
    docs.push(doc);
  }

  await fs.mkdir("./data/stripe_docs", { recursive: true });
  await fs.writeFile(
    "./data/stripe_docs/scraped.json",
    JSON.stringify(docs, null, 2)
  );

  console.log(`✅ Scraped ${docs.length} documents`);
}

main();
```

---

## **Tier 2: Production RAG + Context Management** ⏱️ _Days 4-7_

**Enhanced Features:**

- **Multi-Source Ingestion:**

  - Scrape all 9 data sources listed above
  - Detect and parse different content types using custom parsers:
    - API reference pages (extract JSON examples with `cheerio`)
    - Tutorial articles (step-by-step guides)
    - Error code tables (structured data extraction)
  - Use `RecursiveCharacterTextSplitter` for guides, custom splitter for API refs

- **Metadata Enrichment:**

  - Tag chunks with: `source_url`, `doc_type` (api/guide/support), `category` (billing/webhooks/payments), `last_updated`, `code_language` (if contains code)
  - Extract code snippets as separate chunks with backreference to parent explanation
  - Use regex to detect code blocks and programming languages

- **Hybrid Search:**

  - Implement BM25 keyword search using `natural` library or `flexsearch`
  - Combine semantic (Pinecone) + keyword (BM25) scores with 0.7/0.3 weighting
  - Especially important for exact error codes (e.g., "card_declined")
  - Create fusion ranking algorithm

- **Conversation History:**

  - Maintain sliding window of last 8 messages (4 turns)
  - Use `@langchain/memory` with `BufferWindowMemory`
  - Store in MongoDB for persistence across sessions
  - Include previous Q&A context in retrieval query reformulation

- **Context Windowing:**

  - Track token count using `js-tiktoken`
  - Truncate history if conversation + retrieved docs > 6000 tokens
  - Prioritize most recent turn and highest-relevance chunks

- **Re-ranking:**

  - Implement cross-encoder re-ranking using `@xenova/transformers` (Hugging Face Transformers.js)
  - Model: `cross-encoder/ms-marco-MiniLM-L-6-v2`
  - Re-score top 10 results, return top 4
  - Runs client-side in Node.js (no Python required)

- **Response Improvements:**

  - Cite sources: "According to the [Webhooks Guide](url)..."
  - Show confidence: "Based on the documentation (High confidence)" or "I couldn't find definitive info (Low confidence)"
  - Format code blocks with `markdown-it` for proper rendering
  - Handle edge cases with fallback responses

- **Web UI:**
  - Build **React** chat interface with:
    - Message history display
    - Source citations panel (expandable)
    - Code copy buttons with `react-syntax-highlighter`
    - "Was this helpful?" feedback buttons
  - **Backend:** Express.js REST API
    - `POST /api/chat` – Send message, get response
    - `GET /api/history/:sessionId` – Retrieve conversation
  - **Database:** MongoDB for conversation storage
  - **Styling:** Tailwind CSS for modern UI

**Tech Stack (Additional):**

```json
{
  "dependencies": {
    "express": "^4.18.2",
    "mongodb": "^6.3.0",
    "mongoose": "^8.1.1",
    "natural": "^6.10.0",
    "flexsearch": "^0.7.43",
    "@xenova/transformers": "^2.14.0",
    "markdown-it": "^14.0.0",
    "cors": "^2.8.5"
  },
  "devDependencies": {
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "vite": "^5.1.0",
    "@vitejs/plugin-react": "^4.2.1",
    "tailwindcss": "^3.4.1"
  }
}
```

**Project Structure (Updated):**

```
stripe-support-agent/
├── backend/
│   ├── server.js           # Express API server
│   ├── routes/
│   │   └── chat.js         # Chat endpoints
│   ├── services/
│   │   ├── retriever.js    # Hybrid search
│   │   ├── reranker.js     # Cross-encoder
│   │   └── llm.js          # OpenAI integration
│   ├── models/
│   │   └── Conversation.js # MongoDB schema
│   └── config/
│       └── db.js           # MongoDB connection
├── frontend/
│   ├── src/
│   │   ├── components/
│   │   │   ├── ChatWindow.jsx
│   │   │   ├── MessageList.jsx
│   │   │   ├── SourcePanel.jsx
│   │   │   └── InputBox.jsx
│   │   ├── App.jsx
│   │   └── main.jsx
│   ├── index.html
│   ├── vite.config.js
│   └── tailwind.config.js
├── scripts/
│   ├── scraper.js
│   └── ingest.js
└── package.json
```

**Deliverables:**

- Enhanced scraper with multi-source support
- Hybrid retrieval pipeline (semantic + BM25)
- React chat UI with Tailwind CSS
- Express.js REST API
- MongoDB conversation memory
- Re-ranking with Transformers.js

**Sample Code (Hybrid Search):**

```javascript
import { PineconeStore } from "@langchain/pinecone";
import FlexSearch from "flexsearch";

class HybridRetriever {
  constructor(vectorStore, documents) {
    this.vectorStore = vectorStore;
    this.bm25Index = new FlexSearch.Document({
      tokenize: "forward",
      document: {
        id: "id",
        index: ["content"],
      },
    });

    // Index documents for BM25
    documents.forEach((doc, idx) => {
      this.bm25Index.add({ id: idx, content: doc.pageContent });
    });
    this.documents = documents;
  }

  async retrieve(query, k = 4) {
    // Semantic search
    const semanticResults = await this.vectorStore.similaritySearchWithScore(
      query,
      10
    );

    // Keyword search
    const keywordResults = this.bm25Index.search(query, 10);

    // Fusion ranking (0.7 semantic + 0.3 keyword)
    const merged = this.fuseResults(semanticResults, keywordResults, 0.7, 0.3);

    return merged.slice(0, k);
  }

  fuseResults(semantic, keyword, alpha, beta) {
    // Normalize and combine scores
    const scores = new Map();

    semantic.forEach(([doc, score], idx) => {
      const normalized = 1 / (idx + 1); // Reciprocal rank
      scores.set(
        doc.metadata.id,
        (scores.get(doc.metadata.id) || 0) + alpha * normalized
      );
    });

    keyword.forEach((result, idx) => {
      const docId = result.id;
      const normalized = 1 / (idx + 1);
      scores.set(docId, (scores.get(docId) || 0) + beta * normalized);
    });

    return Array.from(scores.entries())
      .sort((a, b) => b[1] - a[1])
      .map(([id, score]) => ({ document: this.documents[id], score }));
  }
}
```

---

## **Tier 3: MCP + Advanced Agent Features** ⏱️ _Days 8-11_

**Agentic Capabilities:**

- **MCP Tool Integration (using `@modelcontextprotocol/sdk`):**

  1. **Web Search Fallback** (Brave Search MCP server)

     - Install: `npm install @modelcontextprotocol/server-brave-search`
     - Trigger when confidence < 0.6 or no relevant docs found
     - Search: "Stripe [user_query] site:stripe.com OR site:support.stripe.com"
     - Use for recent changes not yet in scraped docs

  2. **Calculator Tool** (Built-in MCP)

     - Use `mathjs` library wrapped as MCP tool
     - Handle: "If I charge 3.2% + $0.30 per transaction, what's the fee on $1,247.50?"
     - Stripe fee calculations for different regions

  3. **Status Page Checker** (Custom MCP server)

     - Check https://status.stripe.com API with `axios`
     - Detect if current issues exist (e.g., "Webhooks experiencing delays")
     - Proactively mention: "Note: Stripe is currently investigating webhook delivery delays"

  4. **Date/Time Tool** (Built-in MCP)

     - Use `date-fns` for time-sensitive queries
     - Handle: "Is Stripe down right now?" (check current time against status page)

  5. **Code Validator** (Custom MCP tool)
     - Validate Stripe API endpoint URLs using regex
     - Check HTTP method compatibility with endpoint
     - Parse code snippets to identify potential errors

- **Multi-Turn Conversations:**

  - Handle follow-ups: "What about recurring payments?" after discussing one-time charges
  - Maintain context: Remember if user mentioned using Node.js SDK vs. REST API
  - Clarification: "Are you asking about Stripe Connect or standard payments?"
  - Context compression: Summarize long conversations every 10 turns using GPT-4

- **Source Attribution:**

  - Display: "Answer synthesized from 3 sources:" with expandable cards
  - Show chunk relevance scores as progress bars
  - Link directly to doc section with anchor tags
  - Track which chunks contributed to each sentence

- **Confidence Scoring:**

  - Calculate based on:
    - Retrieval similarity scores (semantic + keyword)
    - Cross-encoder re-ranking scores
    - Presence of exact entity matches (error codes, API methods)
  - Algorithm: `confidence = 0.4 * avgSemanticScore + 0.3 * rerankerScore + 0.3 * exactMatchBonus`
  - Display: 🟢 High (>0.8) | 🟡 Medium (0.5-0.8) | 🔴 Low (<0.5)
  - Auto-escalate if confidence < 0.5

- **Query Classification:**

  - Classify into: `technical_api`, `billing`, `disputes`, `webhooks`, `account`, `integration`
  - Use few-shot prompting with GPT-4 or fine-tuned model
  - Alternative: Simple rule-based classifier with keyword matching
  - Route to specialized prompt templates per category

- **Feedback Loop:**

  - 👍 👎 buttons on each response
  - Store in MongoDB: `{query, retrieved_chunks, response, feedback, timestamp, sessionId}`
  - Daily aggregation script to identify patterns
  - Auto-retrain retrieval weights based on negative feedback

- **Conversation Analytics:**
  - Track in **PostgreSQL** (for better analytics):
    - Top 20 questions per week (using GROUP BY)
    - Categories with highest "I don't know" rate
    - Avg turns per conversation
    - Escalation rate (when agent defers to human)
  - Use `pg` npm package for database connection
  - Build analytics dashboard with Chart.js or Recharts

**Tech Stack (Additional):**

```json
{
  "dependencies": {
    "@modelcontextprotocol/sdk": "^0.5.0",
    "@modelcontextprotocol/server-brave-search": "^0.2.0",
    "mathjs": "^12.3.2",
    "date-fns": "^3.3.1",
    "pg": "^8.11.3",
    "chart.js": "^4.4.1",
    "react-chartjs-2": "^5.2.0"
  }
}
```

**MCP Integration Example:**

```javascript
import { MCPClient } from "@modelcontextprotocol/sdk/client/index.js";
import { BraveSearchServer } from "@modelcontextprotocol/server-brave-search";

class AgentOrchestrator {
  constructor() {
    this.mcpClient = new MCPClient();
    this.tools = new Map();
  }

  async initializeTools() {
    // Register Brave Search
    const braveSearch = new BraveSearchServer({
      apiKey: process.env.BRAVE_API_KEY,
    });
    await this.mcpClient.connectToServer(braveSearch);

    // Register Calculator
    this.tools.set("calculator", this.createCalculatorTool());

    // Register Status Checker
    this.tools.set("status_checker", this.createStatusTool());
  }

  async decideToolUse(query, confidence) {
    if (confidence < 0.6) {
      return ["web_search"]; // Fallback to web
    }

    if (query.match(/\d+\.\d+%|\$\d+/)) {
      return ["calculator"]; // Contains pricing
    }

    if (query.toLowerCase().includes("down") || query.includes("not working")) {
      return ["status_checker"];
    }

    return []; // No tools needed
  }

  async executeTools(toolNames, query) {
    const results = {};

    for (const toolName of toolNames) {
      if (toolName === "web_search") {
        results.web = await this.mcpClient.callTool("brave_search", {
          query: `Stripe ${query} site:stripe.com`,
        });
      } else if (this.tools.has(toolName)) {
        results[toolName] = await this.tools.get(toolName)(query);
      }
    }

    return results;
  }

  createCalculatorTool() {
    const math = require("mathjs");
    return async (expression) => {
      try {
        // Extract math expressions from natural language
        const matches = expression.match(/[\d\.\+\-\*\/\(\)%]+/g);
        if (matches) {
          return math.evaluate(matches[0]);
        }
      } catch (err) {
        return null;
      }
    };
  }

  createStatusTool() {
    return async () => {
      const response = await axios.get(
        "https://status.stripe.com/api/v2/status.json"
      );
      return response.data.status;
    };
  }
}
```

**Deliverables:**

- 5 MCP tool integrations
- Multi-turn conversation engine with context compression
- Confidence scoring algorithm
- Query classifier
- Feedback collection in MongoDB
- PostgreSQL analytics database
- Analytics dashboard component

---

## **Tier 4: Enterprise-Grade Production System** ⏱️ _Days 12-14_

**Moonshot Features:**

- **Multi-Tenancy:**

  - Support multiple companies (e.g., Stripe + Twilio + Shopify docs)
  - Namespace vector indices: `tenant_{id}_docs` in Pinecone
  - Per-tenant config in PostgreSQL: API keys, usage quotas, custom branding
  - Middleware to inject tenant context on every request

- **Admin Dashboard:**

  - **Knowledge Management:**
    - Upload custom docs via drag-drop (parse PDF/DOCX with `pdf-parse` and `mammoth`)
    - Re-scrape Stripe docs on schedule using `node-cron`
    - View document coverage: % of doc categories indexed
    - Manual chunk editing interface (React + Monaco Editor)
  - **Analytics:**
    - Conversation volume over time (line charts)
    - Top unanswered questions (knowledge gaps table)
    - User satisfaction trends (CSAT line chart)
    - Token usage & cost tracking ($ per conversation pie chart)
  - **Performance Monitoring:**
    - P95 latency per query type (histogram)
    - Cache hit rate for repeated questions
    - Retrieval accuracy metrics
  - Built with: **React** + **Recharts** + **Express** backend

- **A/B Testing Framework:**

  - Test variants stored in PostgreSQL:
    - Chunking: 500 vs 1000 tokens
    - Retrieval: top-3 vs top-5 chunks
    - Prompts: different system prompts
    - Models: GPT-4 vs GPT-4-turbo vs Claude Sonnet
  - Implement with middleware that randomly assigns variant
  - Statistical testing with `simple-statistics` library
  - Auto-promote winning variant after 1000 trials (Chi-square test)

- **Human Handoff:**

  - Detect escalation triggers:
    - User frustration: sentiment analysis with `sentiment` library
    - Account-specific keywords: "suspended", "banned", "locked"
    - Confidence < 0.4 for 3 consecutive turns
  - Create webhook to ticketing system (Zendesk API) with conversation context
  - Seamless transition message in UI

- **Integration Hub:**

  - **Slack Bot:**
    - Use `@slack/bolt` framework
    - Slash command: `/stripe-help [question]`
    - Thread-based conversations with conversation memory
  - **Discord Bot:**
    - Use `discord.js` library
    - React with ✅ when answer marked helpful
  - **Webhooks:**
    - POST to customer's endpoint on events
    - Event types: `conversation.started`, `escalated`, `feedback_received`
    - Signed with HMAC for security
  - **REST API:**
    - `POST /api/chat` – Send message, get response
    - `GET /api/conversations/{id}` – Retrieve history
    - JWT authentication with `jsonwebtoken`
    - Rate limiting with `express-rate-limit`

- **Advanced RAG:**

  - **Query Expansion:**
    - Generate 3 paraphrased versions with GPT-4
    - Retrieve for each, merge with fusion ranking
  - **HyDE (Hypothetical Document Embeddings):**
    - Generate hypothetical ideal answer
    - Embed it, search for similar real docs
  - **Parent-Child Chunks:**
    - Store small chunks (400 tokens) for retrieval
    - Retrieve parent document (2000 tokens) for LLM
    - Track relationships in MongoDB

- **Guardrails:**

  - **PII Detection:**
    - Regex for API keys: `sk_(live|test)_[a-zA-Z0-9]+`
    - Email detection, credit card patterns
    - Mask before logging
  - **Toxicity Filter:**
    - Use `@tensorflow-models/toxicity` (TensorFlow.js)
    - Block profanity, harassment
  - **Prompt Injection Defense:**
    - Detect patterns: "ignore previous", "system:"
    - Sanitize with `validator` library
  - **Rate Limiting:**
    - Redis-based token bucket with `ioredis`
    - 20 messages per user per hour

- **Evaluation Suite:**
  - **Golden Q&A Dataset:**
    - Store in JSON: 200 Stripe questions with verified answers
    - Cover all doc categories
  - **Automated Testing:**
    - Run golden set with `jest` on every deploy
    - Calculate accuracy metrics
    - RAGAS-style metrics (faithfulness, relevance)
  - **CI/CD Integration:**
    - GitHub Actions workflow
    - Alert if metrics drop >5%
    - Automated deployment to production

**Tech Stack (Additional):**

```json
{
  "dependencies": {
    "@slack/bolt": "^3.17.1",
    "discord.js": "^14.14.1",
    "jsonwebtoken": "^9.0.2",
    "express-rate-limit": "^7.1.5",
    "ioredis": "^5.3.2",
    "node-cron": "^3.0.3",
    "pdf-parse": "^1.1.1",
    "mammoth": "^1.6.0",
    "sentiment": "^5.0.2",
    "@tensorflow-models/toxicity": "^1.2.2",
    "validator": "^13.11.0",
    "simple-statistics": "^7.8.3"
  },
  "devDependencies": {
    "jest": "^29.7.0",
    "@testing-library/react": "^14.2.1"
  }
}
```

**Project Structure (Final):**

```
stripe-support-agent/
├── backend/
│   ├── server.js
│   ├── routes/
│   │   ├── chat.js
│   │   ├── admin.js
│   │   ├── webhooks.js
│   │   └── analytics.js
│   ├── services/
│   │   ├── rag/
│   │   │   ├── retriever.js
│   │   │   ├── reranker.js
│   │   │   ├── hyde.js
│   │   │   └── query-expansion.js
│   │   ├── mcp/
│   │   │   ├── orchestrator.js
│   │   │   └── tools/
│   │   ├── guardrails/
│   │   │   ├── pii-detector.js
│   │   │   └── toxicity-filter.js
│   │   └── integrations/
│   │       ├── slack-bot.js
│   │       └── discord-bot.js
│   ├── models/
│   │   ├── Conversation.js
│   │   ├── Tenant.js
│   │   └── Analytics.js
│   ├── middleware/
│   │   ├── auth.js
│   │   ├── rate-limit.js
│   │   └── tenant.js
│   └── config/
├── frontend/
│   ├── src/
│   │   ├── components/
│   │   │   ├── chat/
│   │   │   ├── admin/
│   │   │   └── analytics/
│   │   ├── pages/
│   │   │   ├── Chat.jsx
│   │   │   ├── Admin.jsx
│   │   │   └── Dashboard.jsx
│   │   └── App.jsx
├── scripts/
│   ├── scraper.js
│   ├── ingest.js
│   ├── cron-rescrape.js
│   └── run-evaluation.js
├── tests/
│   ├── golden-qa.json
│   └── integration.test.js
├── .github/
│   └── workflows/
│       └── ci-cd.yml
└── docker-compose.yml
```

**Deliverables:**

- Full admin dashboard (React)
- Multi-tenant architecture with namespace isolation
- A/B testing framework with statistical analysis
- Slack + Discord bot integration
- Advanced RAG (HyDE + query expansion + parent-child)
- Comprehensive guardrails (PII, toxicity, rate limiting)
- Automated evaluation suite with CI/CD
- Docker containerization with docker-compose
- Production deployment guide (AWS/Vercel)

---

## 📊 **Success Metrics**

Track these KPIs to measure agent effectiveness:

| Metric                 | Tier 1            | Tier 2                  | Tier 3       | Tier 4            |
| ---------------------- | ----------------- | ----------------------- | ------------ | ----------------- |
| **Answer Accuracy**    | Manual spot-check | >70% helpful (feedback) | >80% helpful | >85% (RAGAS)      |
| **Avg Response Time**  | <5s               | <3s                     | <2s (cached) | <1.5s (optimized) |
| **Escalation Rate**    | N/A               | N/A                     | <20%         | <15%              |
| **User Satisfaction**  | N/A               | Thumbs up/down          | CSAT score   | >4.2/5 CSAT       |
| **Knowledge Coverage** | 3 doc sections    | All 9 sources           | + web search | + custom docs     |

---

## 🚀 **2-Week Timeline**

### **Week 1: Core RAG System**

- **Days 1-3 (Tier 1):** Basic scraper, embedding pipeline, terminal chat
- **Days 4-7 (Tier 2):** Multi-source scraping, React UI, Express API, hybrid search, MongoDB integration

### **Week 2: Advanced Features & Production**

- **Days 8-11 (Tier 3):** MCP tools, confidence scoring, analytics, multi-turn conversations
- **Days 12-14 (Tier 4):** Admin dashboard, guardrails, integrations, deployment, testing

**Daily Breakdown:**

| Day | Focus                       | Deliverable              |
| --- | --------------------------- | ------------------------ |
| 1   | Scraper setup               | 3 sources scraped        |
| 2   | Embedding & vector DB       | Pinecone index populated |
| 3   | Terminal chat               | Basic Q&A working        |
| 4   | Multi-source scraper        | All 9 sources scraped    |
| 5   | Hybrid search + reranking   | Improved retrieval       |
| 6   | React UI + Express API      | Web interface            |
| 7   | Conversation memory         | Multi-turn working       |
| 8   | MCP tool integration        | 3+ tools connected       |
| 9   | Confidence & classification | Smart routing            |
| 10  | Analytics dashboard         | PostgreSQL + charts      |
| 11  | Feedback loop               | Thumbs up/down           |
| 12  | Admin panel                 | Knowledge management     |
| 13  | Guardrails + testing        | Security + CI/CD         |
| 14  | Deployment + polish         | Production-ready         |

---

## 🚀 **Quick Start**

```bash
# Clone starter template
git clone <repo-url> stripe-support-agent
cd stripe-support-agent

# Install dependencies
npm install

# Set up environment
cp .env.example .env
# Add: OPENAI_API_KEY, PINECONE_API_KEY, PINECONE_INDEX_NAME, MONGODB_URI

# Scrape Stripe docs (Tier 1: 3 sources)
node scripts/scraper.js --sources api,webhooks,errors --limit 50

# Ingest into Pinecone
node scripts/ingest.js

# Start terminal chat (Tier 1)
node src/chat.js

# OR start web app (Tier 2+)
npm run dev:backend  # Terminal 1
npm run dev:frontend # Terminal 2
# Open http://localhost:5173
```

**Sample Interaction:**

```
You: How do I verify webhook signatures in Node.js?

Agent: [🟢 High Confidence - 0.89]

To verify webhook signatures in Node.js, Stripe signs each webhook with your
endpoint's secret. Here's how to verify:

[Code block showing Node.js example]

📚 Sources:
- Webhooks Guide (stripe.com/docs/webhooks)
- Node.js SDK Reference

Was this helpful? 👍 👎
```

---

## ⚠️ **Ethical Scraping Guidelines**

- ✅ Stripe's docs are publicly accessible and meant for developer use
- ✅ Respect `robots.txt` – Stripe allows doc crawling
- ✅ Implement 1 req/sec rate limit during scraping
- ✅ Cache scraped content – don't re-scrape on every run
- ✅ Use official API when available (Stripe doesn't have doc API)
- ❌ Never scrape user dashboards or authenticated content
- ❌ Don't republish Stripe's docs verbatim (use for retrieval only)

---

## 🎓 **Learning Outcomes**

By building this agent in 2 weeks, you'll master:

- **Week 1:** RAG fundamentals, vector databases, React/Express full-stack, hybrid search, conversation memory
- **Week 2:** MCP tool orchestration, agent reasoning, analytics, production deployment, testing & CI/CD

This project evolves from a weekend prototype to a production-ready system that could genuinely reduce Stripe's support ticket volume. **Every tier is immediately deployable and useful**, with clear 2-week milestones.
