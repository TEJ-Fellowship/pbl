# Shopify Merchant Support Agent - Tier 2 Implementation

## ğŸš€ Overview

This is a **Tier 2** implementation of the Shopify Merchant Support Agent featuring:

- **Conversation Memory**: Sliding window of last 8 messages (4 turns) with MongoDB persistence
- **Context Windowing**: Token counting and intelligent truncation using js-tiktoken
- **Web UI**: Modern React chat interface with Tailwind CSS
- **Source Citations**: Expandable panel with code copy functionality
- **Feedback System**: "Was this helpful?" buttons for continuous improvement

## ğŸ—ï¸ Architecture

### Backend (Express.js + MongoDB)

```
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ mongodb.js          # MongoDB connection
â”‚   â””â”€â”€ pinecone.js         # Pinecone vector DB config
â”œâ”€â”€ controllers/
â”‚   â””â”€â”€ ChatController.js   # API endpoints
â”œâ”€â”€ models/
â”‚   â””â”€â”€ Conversation.js     # MongoDB schema
â”œâ”€â”€ routes/
â”‚   â””â”€â”€ route.js            # Express routes
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ memory/
â”‚   â”‚   â””â”€â”€ MongoDBBufferWindowMemory.js  # LangChain memory with MongoDB
â”‚   â”œâ”€â”€ context/
â”‚   â”‚   â””â”€â”€ ContextWindowManager.js       # Token counting & truncation
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ EnhancedChatService.js        # Main chat service
â”‚   â””â”€â”€ hybrid-retriever.js              # Existing hybrid search
â””â”€â”€ server.js              # Express server
```

### Frontend (React + Tailwind CSS)

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ SourceCitations.jsx    # Sources panel
â”‚   â”‚   â””â”€â”€ LoadingDots.jsx        # Loading animation
â”‚   â”œâ”€â”€ App.jsx                    # Main chat interface
â”‚   â”œâ”€â”€ index.css                  # Tailwind styles
â”‚   â””â”€â”€ main.jsx                   # React entry point
â”œâ”€â”€ tailwind.config.js             # Tailwind configuration
â””â”€â”€ postcss.config.js             # PostCSS configuration
```

## ğŸ”§ Key Features

### 1. Conversation Memory

- **BufferWindowMemory**: Maintains last 8 messages (4 turns)
- **MongoDB Persistence**: Conversations survive server restarts
- **Session Management**: Unique session IDs for each conversation
- **Cross-session Context**: Previous Q&A context included in retrieval

### 2. Context Windowing

- **Token Counting**: Uses js-tiktoken for accurate token counting
- **Smart Truncation**: Prioritizes recent messages and high-relevance chunks
- **6000 Token Limit**: Configurable maximum context size
- **Efficient Management**: Balances conversation history with retrieved docs

### 3. Web UI Features

- **Modern Design**: Clean, responsive interface with Tailwind CSS
- **Real-time Chat**: Instant message sending and receiving
- **Source Citations**: Expandable panel showing document sources
- **Code Highlighting**: Syntax highlighting with react-syntax-highlighter
- **Copy Functionality**: One-click copying of messages and code
- **Feedback System**: Thumbs up/down for response quality
- **Loading States**: Smooth loading animations

## ğŸš€ Quick Start

### Prerequisites

- Node.js 18.17.0+
- MongoDB (local or cloud)
- Gemini API key
- Pinecone API key

### Backend Setup

```bash
cd backend
npm install
cp env.example .env
# Edit .env with your API keys
npm run dev
```

### Frontend Setup

```bash
cd frontend
npm install
npm run dev
```

### Environment Variables

```env
MONGODB_URI=mongodb://localhost:27017/shopify_support
GEMINI_API_KEY=your_gemini_api_key
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_ENVIRONMENT=your_pinecone_environment
PINECONE_INDEX_NAME=shopify-support
PORT=3000
```

## ğŸ“¡ API Endpoints

### POST /api/chat

Send a message and get AI response with memory context.

**Request:**

```json
{
  "message": "How do I create a product using the API?",
  "sessionId": "optional-session-id"
}
```

**Response:**

```json
{
  "success": true,
  "data": {
    "response": "To create a product using the Shopify API...",
    "sources": [
      {
        "title": "Product API Documentation",
        "url": "https://shopify.dev/docs/api/admin-rest/products",
        "score": 0.95,
        "chunk": "Creating products via API..."
      }
    ],
    "sessionId": "uuid-session-id",
    "timestamp": "2024-01-01T00:00:00.000Z",
    "contextStats": {
      "messageTokens": 150,
      "docTokens": 800,
      "totalTokens": 950,
      "utilizationPercent": 15.8
    }
  }
}
```

### GET /api/history/:sessionId

Retrieve conversation history for a session.

### POST /api/feedback

Update feedback for a specific message.

### DELETE /api/chat/:sessionId

Clear conversation history for a session.

### POST /api/session

Generate a new session ID.

## ğŸ§  Mental Visualization

### Conversation Flow

```
User Message â†’ Memory Load â†’ Hybrid Search â†’ Context Window â†’ LLM â†’ Response â†’ Memory Save
     â†“              â†“            â†“            â†“         â†“        â†“         â†“
  Session ID    Last 8 msgs   Pinecone +   Token      Gemini   Sources   MongoDB
                from MongoDB  FlexSearch   Count      AI       + Stats   Storage
```

### Context Management

```
Total Context (6000 tokens max)
â”œâ”€â”€ Conversation History (sliding window)
â”‚   â”œâ”€â”€ Recent messages (priority)
â”‚   â””â”€â”€ Older messages (truncated if needed)
â”œâ”€â”€ Retrieved Documents (top 6 by relevance)
â”‚   â”œâ”€â”€ High-score chunks (priority)
â”‚   â””â”€â”€ Lower-score chunks (truncated if needed)
â””â”€â”€ Response Buffer (1000 tokens reserved)
```

### Memory Architecture

```
MongoDB Collection: conversations
â”œâ”€â”€ sessionId (indexed)
â”œâ”€â”€ messages[] (last 8)
â”‚   â”œâ”€â”€ role: 'user' | 'assistant'
â”‚   â”œâ”€â”€ content: string
â”‚   â”œâ”€â”€ timestamp: Date
â”‚   â”œâ”€â”€ sources: array
â”‚   â””â”€â”€ feedback: object
â”œâ”€â”€ createdAt: Date
â””â”€â”€ updatedAt: Date
```

## ğŸ¯ Key Benefits

1. **Persistent Memory**: Conversations continue across sessions
2. **Intelligent Context**: Token-aware truncation prevents overflow
3. **Source Transparency**: Users can verify information sources
4. **Feedback Loop**: Continuous improvement through user feedback
5. **Modern UX**: Professional chat interface with smooth animations
6. **Scalable Architecture**: Clean separation of concerns

## ğŸ” Technical Highlights

- **LangChain Integration**: Uses @langchain/memory for conversation management
- **Token Precision**: js-tiktoken for accurate GPT token counting
- **Hybrid Search**: Combines semantic (Pinecone) + keyword (FlexSearch)
- **Real-time UI**: React with modern hooks and state management
- **Responsive Design**: Mobile-friendly Tailwind CSS styling
- **Error Handling**: Comprehensive error handling and user feedback

## ğŸš€ Production Ready

This implementation is production-ready with:

- âœ… Comprehensive error handling
- âœ… Input validation and sanitization
- âœ… CORS configuration
- âœ… Environment-based configuration
- âœ… Database indexing for performance
- âœ… Responsive UI design
- âœ… Loading states and user feedback
- âœ… Clean code architecture

The system successfully implements all Tier 2 requirements with professional-grade code quality and user experience.
